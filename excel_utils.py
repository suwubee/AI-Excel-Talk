import pandas as pd
import openpyxl
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
from openpyxl.utils import get_column_letter
from openpyxl.worksheet.table import Table, TableStyleInfo
import numpy as np
from typing import Dict, List, Any, Tuple, Optional
import io
import tempfile
import os

class AdvancedExcelProcessor:
    """é«˜çº§Excelå¤„ç†ç±»"""
    
    def __init__(self):
        self.workbook = None
        self.file_path = None
        self.modified_data = {}
    
    def load_excel(self, file_path: str) -> Dict[str, pd.DataFrame]:
        """åŠ è½½Excelæ–‡ä»¶å¹¶è¿”å›æ‰€æœ‰å·¥ä½œè¡¨çš„æ•°æ®"""
        self.file_path = file_path
        self.workbook = openpyxl.load_workbook(file_path, data_only=False)
        
        excel_data = {}
        for sheet_name in self.workbook.sheetnames:
            df, _ = self.read_excel_with_merged_cells(file_path, sheet_name)
            excel_data[sheet_name] = df
            self.modified_data[sheet_name] = df.copy()
        
        return excel_data
    
    @staticmethod
    def read_excel_with_merged_cells(file_path: str, sheet_name: str = None, max_rows: int = 1000) -> Tuple[pd.DataFrame, str]:
        """è¯»å–Excelæ–‡ä»¶å¹¶å¤„ç†åˆå¹¶å•å…ƒæ ¼ï¼Œæ”¯æŒæ›´å¤šè¡Œæ•°"""
        try:
            wb = openpyxl.load_workbook(file_path, data_only=True)
            
            if sheet_name is None:
                sheet_name = wb.sheetnames[0]
            
            ws = wb[sheet_name]
            
            # è·å–åˆå¹¶å•å…ƒæ ¼ä¿¡æ¯
            merged_cells = ws.merged_cells.ranges
            merged_dict = {}
            
            # åˆ›å»ºåˆå¹¶å•å…ƒæ ¼æ˜ å°„
            for merged_range in merged_cells:
                top_left_cell = ws.cell(row=merged_range.min_row, column=merged_range.min_col)
                top_left_value = top_left_cell.value
                
                for row in range(merged_range.min_row, merged_range.max_row + 1):
                    for col in range(merged_range.min_col, merged_range.max_col + 1):
                        merged_dict[(row, col)] = top_left_value
            
            # è¯»å–æ•°æ®
            data = []
            max_col = min(ws.max_column, 100)  # é™åˆ¶æœ€å¤§åˆ—æ•°
            max_row = min(ws.max_row, max_rows)
            
            for row in range(1, max_row + 1):
                row_data = []
                for col in range(1, max_col + 1):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯åˆå¹¶å•å…ƒæ ¼
                    if (row, col) in merged_dict:
                        value = merged_dict[(row, col)]
                    else:
                        cell = ws.cell(row=row, column=col)
                        value = cell.value
                    
                    row_data.append(value if value is not None else "")
                
                data.append(row_data)
            
            # è½¬æ¢ä¸ºDataFrame
            if data and len(data) > 1:
                # ä½¿ç”¨ç¬¬ä¸€è¡Œä½œä¸ºåˆ—åï¼Œç¡®ä¿åˆ—åæ˜¯å­—ç¬¦ä¸²
                columns = []
                column_counts = {}  # ç”¨äºè·Ÿè¸ªé‡å¤åˆ—å
                
                for i, col in enumerate(data[0]):
                    if col is None or str(col).strip() == "":
                        base_name = f"åˆ—{i+1}"
                    else:
                        base_name = str(col).strip()
                    
                    # å¤„ç†é‡å¤åˆ—å
                    if base_name in column_counts:
                        column_counts[base_name] += 1
                        unique_name = f"{base_name}_{column_counts[base_name]}"
                    else:
                        column_counts[base_name] = 0
                        unique_name = base_name
                    
                    columns.append(unique_name)
                
                # åˆ›å»ºDataFrameï¼Œç¡®ä¿æ•°æ®è¡Œå­˜åœ¨
                data_rows = data[1:] if len(data) > 1 else []
                if data_rows:
                    df = pd.DataFrame(data_rows, columns=columns)
                else:
                    df = pd.DataFrame(columns=columns)
            else:
                df = pd.DataFrame()
            
            # æ¸…ç†æ•°æ® - æ·»åŠ é”™è¯¯å¤„ç†
            try:
                if not df.empty:
                    # ä¿®å¤pandas FutureWarningå¹¶ç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´
                    df = df.replace('', np.nan)
                    
                    # å¯¹æ¯åˆ—è¿›è¡Œæ•°æ®ç±»å‹è§„èŒƒåŒ–ï¼Œé¿å…æ··åˆç±»å‹
                    for col in df.columns:
                        try:
                            # æ£€æŸ¥åˆ—æ˜¯å¦åŒ…å«æ··åˆç±»å‹
                            if df[col].dtype == 'object':
                                # å°è¯•å°†å…¨éƒ¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œé¿å…æ··åˆç±»å‹
                                df[col] = df[col].astype(str)
                                # å°†å­—ç¬¦ä¸²'nan'é‡æ–°æ›¿æ¢ä¸ºçœŸæ­£çš„NaN
                                df[col] = df[col].replace('nan', np.nan)
                        except Exception as e:
                            print(f"åˆ— {col} æ•°æ®ç±»å‹è½¬æ¢è­¦å‘Š: {e}")
                            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œå¼ºåˆ¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                            df[col] = df[col].astype(str).replace('nan', np.nan)
                    
                    # æœ€ååº”ç”¨infer_objects
                    df = df.infer_objects(copy=False)
                    
                    # æ¸…ç†åˆ—åä¸­çš„ç‰¹æ®Šå­—ç¬¦
                    df.columns = [str(col).replace('\n', ' ').replace('\r', ' ').strip() for col in df.columns]
            except Exception as e:
                print(f"æ•°æ®æ¸…ç†æ—¶å‡ºç°é—®é¢˜: {e}")
                # å¦‚æœæ¸…ç†å¤±è´¥ï¼Œè‡³å°‘ç¡®ä¿åŸºæœ¬çš„æ•°æ®ç»“æ„
                if not df.empty:
                    try:
                        df.columns = [str(col).replace('\n', ' ').replace('\r', ' ').strip() for col in df.columns]
                    except:
                        pass
            
            # ç”Ÿæˆmarkdownæ ¼å¼é¢„è§ˆ
            markdown_content = AdvancedExcelProcessor.df_to_markdown(df, sheet_name)
            
            return df, markdown_content
            
        except Exception as e:
            raise Exception(f"è¯»å–Excelæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    
    @staticmethod
    def df_to_markdown(df: pd.DataFrame, sheet_name: str = "") -> str:
        """å°†DataFrameè½¬æ¢ä¸ºMarkdownæ ¼å¼ï¼Œæ”¯æŒæ›´å¥½çš„æ ¼å¼åŒ–"""
        if df.empty:
            return f"## ğŸ“‹ {sheet_name}\n\n*æ­¤å·¥ä½œè¡¨ä¸ºç©º*\n\n"
        
        markdown = f"## ğŸ“‹ {sheet_name}\n\n"
        
        # æ•°æ®åŸºæœ¬ä¿¡æ¯
        markdown += f"**æ•°æ®æ¦‚è§ˆ**: {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—\n\n"
        
        # é™åˆ¶æ˜¾ç¤ºçš„è¡Œæ•°å’Œåˆ—æ•°
        display_rows = min(20, len(df))
        display_cols = min(8, len(df.columns))
        display_df = df.head(display_rows).iloc[:, :display_cols]
        
        # å¤„ç†åˆ—åï¼Œç¡®ä¿ä¸ä¼šå¤ªé•¿
        headers = ["#"] + [str(col)[:15] + "..." if len(str(col)) > 15 else str(col) for col in display_df.columns]
        markdown += "| " + " | ".join(headers) + " |\n"
        markdown += "| " + " | ".join(["---"] * len(headers)) + " |\n"
        
        # æ·»åŠ æ•°æ®è¡Œ
        for idx, row in display_df.iterrows():
            row_data = [str(idx + 1)]  # è¡Œå·ä»1å¼€å§‹
            for val in row:
                str_val = str(val) if pd.notna(val) else ""
                # é™åˆ¶å•å…ƒæ ¼å†…å®¹é•¿åº¦
                if len(str_val) > 20:
                    str_val = str_val[:17] + "..."
                row_data.append(str_val)
            markdown += "| " + " | ".join(row_data) + " |\n"
        
        # æ·»åŠ çœç•¥ä¿¡æ¯
        if len(df) > display_rows:
            markdown += f"\n*ğŸ“ ä»…æ˜¾ç¤ºå‰{display_rows}è¡Œï¼Œæ€»å…±{len(df)}è¡Œ*\n"
        
        if len(df.columns) > display_cols:
            markdown += f"*ğŸ“Š ä»…æ˜¾ç¤ºå‰{display_cols}åˆ—ï¼Œæ€»å…±{len(df.columns)}åˆ—*\n"
        
        # æ·»åŠ æ•°æ®ç±»å‹ä¿¡æ¯ - ä¿®å¤é”™è¯¯å¤„ç†
        markdown += "\n### ğŸ“ˆ æ•°æ®ç±»å‹æ¦‚è§ˆ\n"
        try:
            cols_to_show = list(df.columns)[:5]  # åªæ˜¾ç¤ºå‰5åˆ—çš„ç±»å‹
            for col in cols_to_show:
                try:
                    if col in df.columns:
                        dtype = str(df[col].dtype)
                        non_null_count = df[col].count()
                        markdown += f"- **{col}**: {dtype} ({non_null_count}/{len(df)} éç©º)\n"
                except Exception as e:
                    # å¦‚æœè·å–æŸåˆ—çš„æ•°æ®ç±»å‹å¤±è´¥ï¼Œè·³è¿‡è¯¥åˆ—
                    markdown += f"- **{col}**: æœªçŸ¥ç±»å‹\n"
            
            if len(df.columns) > 5:
                markdown += f"- *... è¿˜æœ‰ {len(df.columns) - 5} åˆ—*\n"
        except Exception as e:
            markdown += "- *æ•°æ®ç±»å‹ä¿¡æ¯è·å–å¤±è´¥*\n"
        
        return markdown
    
    def update_dataframe(self, sheet_name: str, df: pd.DataFrame):
        """æ›´æ–°æŒ‡å®šå·¥ä½œè¡¨çš„æ•°æ®"""
        self.modified_data[sheet_name] = df
    
    def add_calculated_column(self, sheet_name: str, column_name: str, formula_func, description: str = ""):
        """æ·»åŠ è®¡ç®—åˆ—"""
        if sheet_name in self.modified_data:
            df = self.modified_data[sheet_name]
            try:
                df[column_name] = formula_func(df)
                self.modified_data[sheet_name] = df
                return True, f"æˆåŠŸæ·»åŠ è®¡ç®—åˆ—: {column_name}"
            except Exception as e:
                return False, f"æ·»åŠ è®¡ç®—åˆ—å¤±è´¥: {str(e)}"
        return False, "å·¥ä½œè¡¨ä¸å­˜åœ¨"
    
    def fill_missing_values(self, sheet_name: str, column: str, method: str = "mean", custom_value=None):
        """å¡«å……ç¼ºå¤±å€¼"""
        if sheet_name not in self.modified_data:
            return False, "å·¥ä½œè¡¨ä¸å­˜åœ¨"
        
        df = self.modified_data[sheet_name]
        if column not in df.columns:
            return False, f"åˆ— '{column}' ä¸å­˜åœ¨"
        
        try:
            if method == "mean" and pd.api.types.is_numeric_dtype(df[column]):
                df[column].fillna(df[column].mean(), inplace=True)
            elif method == "median" and pd.api.types.is_numeric_dtype(df[column]):
                df[column].fillna(df[column].median(), inplace=True)
            elif method == "mode":
                mode_value = df[column].mode().iloc[0] if not df[column].mode().empty else ""
                df[column].fillna(mode_value, inplace=True)
            elif method == "forward":
                df[column].fillna(method='ffill', inplace=True)
            elif method == "backward":
                df[column].fillna(method='bfill', inplace=True)
            elif method == "custom" and custom_value is not None:
                df[column].fillna(custom_value, inplace=True)
            else:
                return False, f"ä¸æ”¯æŒçš„å¡«å……æ–¹æ³•: {method}"
            
            self.modified_data[sheet_name] = df
            return True, f"æˆåŠŸå¡«å……åˆ— '{column}' çš„ç¼ºå¤±å€¼"
            
        except Exception as e:
            return False, f"å¡«å……å¤±è´¥: {str(e)}"
    
    def add_summary_statistics(self, sheet_name: str, target_columns: List[str] = None):
        """æ·»åŠ æ±‡æ€»ç»Ÿè®¡"""
        if sheet_name not in self.modified_data:
            return False, "å·¥ä½œè¡¨ä¸å­˜åœ¨"
        
        df = self.modified_data[sheet_name]
        
        try:
            if target_columns is None:
                target_columns = df.select_dtypes(include=[np.number]).columns.tolist()
            
            if not target_columns:
                return False, "æ²¡æœ‰æ‰¾åˆ°æ•°å€¼åˆ—"
            
            # åˆ›å»ºæ±‡æ€»ç»Ÿè®¡
            summary_data = []
            for col in target_columns:
                if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):
                    stats = {
                        'åˆ—å': col,
                        'è®¡æ•°': df[col].count(),
                        'å‡å€¼': df[col].mean(),
                        'ä¸­ä½æ•°': df[col].median(),
                        'æ ‡å‡†å·®': df[col].std(),
                        'æœ€å°å€¼': df[col].min(),
                        'æœ€å¤§å€¼': df[col].max(),
                        'ç¼ºå¤±å€¼': df[col].isnull().sum()
                    }
                    summary_data.append(stats)
            
            if summary_data:
                summary_df = pd.DataFrame(summary_data)
                summary_sheet_name = f"{sheet_name}_ç»Ÿè®¡æ±‡æ€»"
                self.modified_data[summary_sheet_name] = summary_df
                return True, f"æˆåŠŸåˆ›å»ºç»Ÿè®¡æ±‡æ€»å·¥ä½œè¡¨: {summary_sheet_name}"
            else:
                return False, "æ²¡æœ‰å¯ç»Ÿè®¡çš„æ•°å€¼æ•°æ®"
                
        except Exception as e:
            return False, f"åˆ›å»ºç»Ÿè®¡æ±‡æ€»å¤±è´¥: {str(e)}"
    
    def export_to_excel(self, output_path: str = None) -> str:
        """å¯¼å‡ºä¿®æ”¹åçš„æ•°æ®åˆ°Excelæ–‡ä»¶"""
        try:
            if output_path is None:
                timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
                output_path = f"modified_excel_{timestamp}.xlsx"
            
            # åˆ›å»ºæ–°çš„å·¥ä½œç°¿
            wb = openpyxl.Workbook()
            wb.remove(wb.active)  # åˆ é™¤é»˜è®¤å·¥ä½œè¡¨
            
            for sheet_name, df in self.modified_data.items():
                ws = wb.create_sheet(title=sheet_name)
                
                # å†™å…¥åˆ—æ ‡é¢˜
                for col_idx, column in enumerate(df.columns, 1):
                    cell = ws.cell(row=1, column=col_idx, value=column)
                    cell.font = Font(bold=True)
                    cell.fill = PatternFill(start_color="E6E6FA", end_color="E6E6FA", fill_type="solid")
                
                # å†™å…¥æ•°æ®
                for row_idx, row in df.iterrows():
                    for col_idx, value in enumerate(row, 1):
                        ws.cell(row=row_idx + 2, column=col_idx, value=value)
                
                # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
                for column in ws.columns:
                    max_length = 0
                    column_letter = get_column_letter(column[0].column)
                    for cell in column:
                        try:
                            if len(str(cell.value)) > max_length:
                                max_length = len(str(cell.value))
                        except:
                            pass
                    adjusted_width = min(max_length + 2, 50)
                    ws.column_dimensions[column_letter].width = adjusted_width
            
            # ä¿å­˜æ–‡ä»¶
            wb.save(output_path)
            return output_path
            
        except Exception as e:
            raise Exception(f"å¯¼å‡ºExcelæ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def get_data_preview(self, sheet_name: str) -> str:
        """è·å–æ•°æ®é¢„è§ˆ"""
        if sheet_name in self.modified_data:
            df = self.modified_data[sheet_name]
            return self.df_to_markdown(df, sheet_name)
        return "å·¥ä½œè¡¨ä¸å­˜åœ¨"

class DataAnalyzer:
    """æ•°æ®åˆ†æç±»"""
    
    @staticmethod
    def detect_data_types(df: pd.DataFrame) -> Dict[str, str]:
        """æ£€æµ‹æ•°æ®ç±»å‹"""
        type_info = {}
        try:
            for col in df.columns:
                try:
                    if col in df.columns and not df[col].empty:
                        if pd.api.types.is_numeric_dtype(df[col]):
                            if df[col].dtype == 'int64':
                                type_info[col] = "æ•´æ•°"
                            else:
                                type_info[col] = "æµ®ç‚¹æ•°"
                        elif pd.api.types.is_datetime64_any_dtype(df[col]):
                            type_info[col] = "æ—¥æœŸæ—¶é—´"
                        elif pd.api.types.is_bool_dtype(df[col]):
                            type_info[col] = "å¸ƒå°”å€¼"
                        else:
                            type_info[col] = "æ–‡æœ¬"
                    else:
                        type_info[col] = "æœªçŸ¥"
                except Exception as e:
                    type_info[col] = "æ£€æµ‹å¤±è´¥"
        except Exception as e:
            print(f"æ•°æ®ç±»å‹æ£€æµ‹å‡ºé”™: {e}")
        return type_info
    
    @staticmethod
    def find_duplicates(df: pd.DataFrame) -> pd.DataFrame:
        """æŸ¥æ‰¾é‡å¤è¡Œ"""
        try:
            if df.empty:
                return pd.DataFrame()
            duplicates = df[df.duplicated(keep=False)]
            return duplicates
        except Exception as e:
            print(f"æŸ¥æ‰¾é‡å¤æ•°æ®æ—¶å‡ºé”™: {e}")
            return pd.DataFrame()
    
    @staticmethod
    def get_missing_value_report(df: pd.DataFrame) -> pd.DataFrame:
        """è·å–ç¼ºå¤±å€¼æŠ¥å‘Š"""
        missing_data = []
        try:
            for col in df.columns:
                try:
                    missing_count = df[col].isnull().sum()
                    missing_percent = (missing_count / len(df)) * 100 if len(df) > 0 else 0
                    missing_data.append({
                        'åˆ—å': str(col),
                        'ç¼ºå¤±æ•°é‡': missing_count,
                        'ç¼ºå¤±ç™¾åˆ†æ¯”': f"{missing_percent:.2f}%",
                        'æ•°æ®ç±»å‹': str(df[col].dtype) if col in df.columns else "æœªçŸ¥"
                    })
                except Exception as e:
                    missing_data.append({
                        'åˆ—å': str(col),
                        'ç¼ºå¤±æ•°é‡': 0,
                        'ç¼ºå¤±ç™¾åˆ†æ¯”': "0.00%",
                        'æ•°æ®ç±»å‹': "æ£€æµ‹å¤±è´¥"
                    })
        except Exception as e:
            print(f"è·å–ç¼ºå¤±å€¼æŠ¥å‘Šæ—¶å‡ºé”™: {e}")
        
        return pd.DataFrame(missing_data)
    
    @staticmethod
    def detect_outliers(df: pd.DataFrame, method: str = "iqr") -> Dict[str, List]:
        """æ£€æµ‹å¼‚å¸¸å€¼"""
        outliers = {}
        try:
            numeric_columns = df.select_dtypes(include=[np.number]).columns
            
            for col in numeric_columns:
                try:
                    if method == "iqr":
                        Q1 = df[col].quantile(0.25)
                        Q3 = df[col].quantile(0.75)
                        IQR = Q3 - Q1
                        lower_bound = Q1 - 1.5 * IQR
                        upper_bound = Q3 + 1.5 * IQR
                        outlier_indices = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index.tolist()
                        outliers[col] = outlier_indices
                    elif method == "zscore":
                        try:
                            from scipy import stats
                            z_scores = np.abs(stats.zscore(df[col].dropna()))
                            outlier_indices = df[col].dropna().index[z_scores > 3].tolist()
                            outliers[col] = outlier_indices
                        except ImportError:
                            # å¦‚æœscipyä¸å¯ç”¨ï¼Œå›é€€åˆ°IQRæ–¹æ³•
                            Q1 = df[col].quantile(0.25)
                            Q3 = df[col].quantile(0.75)
                            IQR = Q3 - Q1
                            lower_bound = Q1 - 1.5 * IQR
                            upper_bound = Q3 + 1.5 * IQR
                            outlier_indices = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index.tolist()
                            outliers[col] = outlier_indices
                except Exception as e:
                    print(f"æ£€æµ‹åˆ— {col} çš„å¼‚å¸¸å€¼æ—¶å‡ºé”™: {e}")
                    outliers[col] = []
        except Exception as e:
            print(f"å¼‚å¸¸å€¼æ£€æµ‹å‡ºé”™: {e}")
        
        return outliers 