#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ–‡æ¡£åˆ†æåŠŸèƒ½æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯æ–°å¢çš„æ–‡æ¡£åˆ†æåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
from pathlib import Path

def test_imports():
    """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
    print("ğŸ”§ æµ‹è¯•æ¨¡å—å¯¼å…¥...")
    
    try:
        from document_analyzer import DocumentAnalyzer
        print("âœ… DocumentAnalyzer å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ DocumentAnalyzer å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from document_utils import AdvancedDocumentProcessor, DocumentSearchEngine
        print("âœ… DocumentUtils å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ DocumentUtils å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from document_ai_analyzer import EnhancedDocumentAIAnalyzer
        print("âœ… DocumentAIAnalyzer å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ DocumentAIAnalyzer å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    return True

def test_dependencies():
    """æµ‹è¯•ä¾èµ–åŒ…"""
    print("\nğŸ“¦ æµ‹è¯•ä¾èµ–åŒ…...")
    
    dependencies = [
        ('markitdown', 'MarkItDown'),
        ('docx', 'python-docx'),
        ('PyPDF2', 'PyPDF2'),
        ('fitz', 'PyMuPDF'),
        ('PIL', 'Pillow')
    ]
    
    missing_deps = []
    
    for module_name, package_name in dependencies:
        try:
            __import__(module_name)
            print(f"âœ… {package_name} å¯ç”¨")
        except ImportError:
            print(f"âŒ {package_name} ç¼ºå¤±")
            missing_deps.append(package_name)
    
    if missing_deps:
        print(f"\nâš ï¸ ç¼ºå¤±çš„ä¾èµ–åŒ…: {', '.join(missing_deps)}")
        print("è¯·è¿è¡Œ: pip install -r requirements.txt")
        return False
    
    return True

def test_document_analyzer():
    """æµ‹è¯•æ–‡æ¡£åˆ†æå™¨åŸºæœ¬åŠŸèƒ½"""
    print("\nğŸ“Š æµ‹è¯•æ–‡æ¡£åˆ†æå™¨...")
    
    try:
        from document_analyzer import DocumentAnalyzer
        analyzer = DocumentAnalyzer()
        print("âœ… DocumentAnalyzer åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•æ”¯æŒçš„æ–‡æ¡£ç±»å‹
        supported_types = analyzer._detect_document_type("test.docx")
        if supported_types == "docx":
            print("âœ… DOCXç±»å‹æ£€æµ‹æ­£å¸¸")
        
        supported_types = analyzer._detect_document_type("test.pdf")
        if supported_types == "pdf":
            print("âœ… PDFç±»å‹æ£€æµ‹æ­£å¸¸")
        
        return True
        
    except Exception as e:
        print(f"âŒ DocumentAnalyzer æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_document_processor():
    """æµ‹è¯•æ–‡æ¡£å¤„ç†å™¨"""
    print("\nğŸ”§ æµ‹è¯•æ–‡æ¡£å¤„ç†å™¨...")
    
    try:
        from document_utils import AdvancedDocumentProcessor
        processor = AdvancedDocumentProcessor()
        print("âœ… AdvancedDocumentProcessor åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•æ”¯æŒçš„æ ¼å¼
        expected_formats = ['.docx', '.pdf']
        if processor.supported_formats == expected_formats:
            print("âœ… æ”¯æŒçš„æ–‡ä»¶æ ¼å¼é…ç½®æ­£ç¡®")
        
        return True
        
    except Exception as e:
        print(f"âŒ AdvancedDocumentProcessor æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_ai_analyzer():
    """æµ‹è¯•AIåˆ†æå™¨ï¼ˆä¸éœ€è¦çœŸå®API Keyï¼‰"""
    print("\nğŸ¤– æµ‹è¯•AIåˆ†æå™¨...")
    
    try:
        from document_ai_analyzer import EnhancedDocumentAIAnalyzer
        
        # ä½¿ç”¨å‡çš„API Keyè¿›è¡Œåˆå§‹åŒ–æµ‹è¯•
        ai_analyzer = EnhancedDocumentAIAnalyzer("test_key", "https://api.openai.com/v1", "gpt-4o-mini")
        print("âœ… EnhancedDocumentAIAnalyzer åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•ä»»åŠ¡å»ºè®®åŠŸèƒ½
        fake_analysis = {
            'file_info': {'type': 'pdf', 'size_mb': 5},
            'structure_analysis': {'headings': {1: [{'text': 'Test'}]}}
        }
        
        suggestions = ai_analyzer.suggest_analysis_tasks(fake_analysis)
        if len(suggestions) > 0:
            print(f"âœ… åˆ†æä»»åŠ¡å»ºè®®ç”ŸæˆæˆåŠŸ ({len(suggestions)}ä¸ªå»ºè®®)")
        
        return True
        
    except Exception as e:
        print(f"âŒ EnhancedDocumentAIAnalyzer æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_markitdown_functionality():
    """æµ‹è¯•MarkItDownåŠŸèƒ½"""
    print("\nğŸ“ æµ‹è¯•MarkItDownåŠŸèƒ½...")
    
    try:
        from markitdown import MarkItDown
        md = MarkItDown()
        print("âœ… MarkItDown åˆå§‹åŒ–æˆåŠŸ")
        
        # åˆ›å»ºä¸€ä¸ªæµ‹è¯•æ–‡æœ¬æ–‡ä»¶
        test_file = "test_document.txt"
        with open(test_file, 'w', encoding='utf-8') as f:
            f.write("è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£\n\nç”¨äºéªŒè¯MarkItDownåŠŸèƒ½")
        
        # æµ‹è¯•è½¬æ¢
        result = md.convert(test_file)
        if result and hasattr(result, 'text_content'):
            print("âœ… MarkItDown æ–‡æ¡£è½¬æ¢æˆåŠŸ")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        os.remove(test_file)
        
        return True
        
    except Exception as e:
        print(f"âŒ MarkItDown æµ‹è¯•å¤±è´¥: {e}")
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if os.path.exists("test_document.txt"):
            os.remove("test_document.txt")
        return False

def create_sample_documents():
    """åˆ›å»ºç¤ºä¾‹æ–‡æ¡£ç”¨äºæµ‹è¯•"""
    print("\nğŸ“„ åˆ›å»ºç¤ºä¾‹æ–‡æ¡£...")
    
    try:
        # åˆ›å»ºç¤ºä¾‹DOCXæ–‡æ¡£
        from docx import Document
        doc = Document()
        doc.add_heading('æµ‹è¯•æ–‡æ¡£æ ‡é¢˜', 0)
        doc.add_heading('ç¬¬ä¸€ç«  ç®€ä»‹', level=1)
        doc.add_paragraph('è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹æ®µè½ï¼Œç”¨äºæµ‹è¯•æ–‡æ¡£åˆ†æåŠŸèƒ½ã€‚')
        doc.add_heading('ç¬¬äºŒç«  åŠŸèƒ½è¯´æ˜', level=1)
        doc.add_paragraph('æœ¬æ–‡æ¡£åŒ…å«å¤šä¸ªç« èŠ‚å’Œæ®µè½ï¼Œç”¨äºéªŒè¯æ ‡é¢˜è¯†åˆ«å’Œç»“æ„åˆ†æã€‚')
        doc.add_heading('2.1 å­ç« èŠ‚', level=2)
        doc.add_paragraph('è¿™æ˜¯ä¸€ä¸ªå­ç« èŠ‚çš„å†…å®¹ã€‚åŒ…å«å…³é”®è¯ï¼šåˆåŒç¼–å· ABC123ã€‚')
        
        doc.save('sample_document.docx')
        print("âœ… ç¤ºä¾‹DOCXæ–‡æ¡£åˆ›å»ºæˆåŠŸ: sample_document.docx")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç¤ºä¾‹æ–‡æ¡£åˆ›å»ºå¤±è´¥: {e}")
        return False

def test_full_workflow():
    """æµ‹è¯•å®Œæ•´çš„æ–‡æ¡£åˆ†æå·¥ä½œæµ"""
    print("\nğŸ”„ æµ‹è¯•å®Œæ•´å·¥ä½œæµ...")
    
    if not os.path.exists('sample_document.docx'):
        print("âŒ ç¤ºä¾‹æ–‡æ¡£ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œcreate_sample_documents()")
        return False
    
    try:
        from document_analyzer import DocumentAnalyzer
        from document_utils import AdvancedDocumentProcessor
        
        # 1. åˆå§‹åŒ–åˆ†æå™¨
        analyzer = DocumentAnalyzer()
        processor = AdvancedDocumentProcessor()
        
        # 2. åŠ è½½æ–‡æ¡£
        analysis_result = analyzer.analyze_document('sample_document.docx')
        print("âœ… æ–‡æ¡£åŠ è½½å’Œåˆ†æå®Œæˆ")
        
        # 3. æ£€æŸ¥åˆ†æç»“æœç»“æ„
        expected_keys = ['file_info', 'preview_data', 'structure_analysis', 'ai_analysis_data', 'search_capabilities']
        for key in expected_keys:
            if key in analysis_result:
                print(f"âœ… {key} æ•°æ®ç»“æ„æ­£ç¡®")
            else:
                print(f"âŒ {key} æ•°æ®ç¼ºå¤±")
        
        # 4. æµ‹è¯•æœç´¢åŠŸèƒ½
        search_results = analyzer.search_keyword_context("åˆåŒç¼–å·", context_lines=2)
        if search_results:
            print(f"âœ… å…³é”®è¯æœç´¢åŠŸèƒ½æ­£å¸¸ (æ‰¾åˆ°{len(search_results)}ä¸ªç»“æœ)")
        else:
            print("âš ï¸ å…³é”®è¯æœç´¢æ— ç»“æœï¼ˆè¿™å¯èƒ½æ˜¯æ­£å¸¸çš„ï¼‰")
        
        # 5. æµ‹è¯•ä»£ç ç”Ÿæˆ
        code = analyzer.generate_analysis_code("æœç´¢æ–‡æ¡£ä¸­çš„å…³é”®ä¿¡æ¯")
        if code and len(code) > 100:
            print("âœ… ä»£ç ç”ŸæˆåŠŸèƒ½æ­£å¸¸")
        
        return True
        
    except Exception as e:
        print(f"âŒ å®Œæ•´å·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}")
        return False

def cleanup():
    """æ¸…ç†æµ‹è¯•æ–‡ä»¶"""
    print("\nğŸ§¹ æ¸…ç†æµ‹è¯•æ–‡ä»¶...")
    
    test_files = ['sample_document.docx', 'test_document.txt']
    for file in test_files:
        if os.path.exists(file):
            os.remove(file)
            print(f"âœ… å·²åˆ é™¤: {file}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ æ–‡æ¡£åˆ†æåŠŸèƒ½æµ‹è¯•å¼€å§‹")
    print("=" * 50)
    
    # æµ‹è¯•æ­¥éª¤
    tests = [
        ("æ¨¡å—å¯¼å…¥", test_imports),
        ("ä¾èµ–åŒ…æ£€æŸ¥", test_dependencies),
        ("æ–‡æ¡£åˆ†æå™¨", test_document_analyzer),
        ("æ–‡æ¡£å¤„ç†å™¨", test_document_processor),
        ("AIåˆ†æå™¨", test_ai_analyzer),
        ("MarkItDownåŠŸèƒ½", test_markitdown_functionality),
    ]
    
    results = []
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å‡ºç°å¼‚å¸¸: {e}")
            results.append((test_name, False))
    
    # å¦‚æœåŸºç¡€æµ‹è¯•éƒ½é€šè¿‡ï¼Œè¿›è¡Œé«˜çº§æµ‹è¯•
    if all(result for _, result in results):
        print(f"\n{'='*20} é«˜çº§æµ‹è¯• {'='*20}")
        
        # åˆ›å»ºç¤ºä¾‹æ–‡æ¡£
        if create_sample_documents():
            # å®Œæ•´å·¥ä½œæµæµ‹è¯•
            workflow_result = test_full_workflow()
            results.append(("å®Œæ•´å·¥ä½œæµ", workflow_result))
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        cleanup()
    
    # æ€»ç»“ç»“æœ
    print("\n" + "="*50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
    print("="*50)
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name:<20} {status}")
        if result:
            passed += 1
    
    print(f"\næ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ–‡æ¡£åˆ†æåŠŸèƒ½å·²å‡†å¤‡å°±ç»ªã€‚")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¾èµ–å®‰è£…å’Œé…ç½®ã€‚")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 