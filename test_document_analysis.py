#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ–‡æ¡£åˆ†æåŠŸèƒ½æµ‹è¯•è„šæœ¬ - éªŒè¯å¢å¼ºåŠŸèƒ½
æµ‹è¯•å†…å®¹ï¼š
1. ç»“æ„åŒ–åˆ†æä¸ç¼©ç•¥æ˜¾ç¤ºï¼ˆ100ä¸ªä»¥å†…å…¨éƒ¨æ˜¾ç¤ºï¼‰
2. å›¾ç‰‡é¢„è§ˆå’Œåˆ†æåŠŸèƒ½
3. æ°´å°æ£€æµ‹åŠŸèƒ½
"""

import os
import sys
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

try:
    from document_analyzer import DocumentAnalyzer
    from document_utils import AdvancedDocumentProcessor
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–: pip install -r requirements.txt")
    sys.exit(1)

def test_enhanced_document_analysis():
    """æµ‹è¯•å¢å¼ºçš„æ–‡æ¡£åˆ†æåŠŸèƒ½"""
    
    print("ğŸ§ª å¼€å§‹æµ‹è¯•å¢å¼ºçš„æ–‡æ¡£åˆ†æåŠŸèƒ½")
    print("=" * 60)
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = AdvancedDocumentProcessor()
    print("âœ… æ–‡æ¡£å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    # æµ‹è¯•æ–‡ä»¶è·¯å¾„ï¼ˆæ‚¨éœ€è¦æ›¿æ¢ä¸ºå®é™…çš„æµ‹è¯•æ–‡ä»¶ï¼‰
    test_files = [
        # "path/to/your/test.docx",
        # "path/to/your/test.pdf"
    ]
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæµ‹è¯•æ–‡ä»¶ï¼Œåˆ›å»ºä¸€ä¸ªç¤ºä¾‹æµ‹è¯•
    if not test_files:
        print("âš ï¸ æœªæŒ‡å®šæµ‹è¯•æ–‡ä»¶ï¼Œå°†åˆ›å»ºæ¨¡æ‹Ÿæµ‹è¯•...")
        test_structure_display_logic()
        return
    
    for file_path in test_files:
        if not os.path.exists(file_path):
            print(f"âš ï¸ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            continue
            
        print(f"\nğŸ“„ æ­£åœ¨æµ‹è¯•æ–‡ä»¶: {Path(file_path).name}")
        print("-" * 40)
        
        try:
            # åŠ è½½å’Œåˆ†ææ–‡æ¡£
            analysis_result = processor.load_document(file_path)
            print("âœ… æ–‡æ¡£åŠ è½½æˆåŠŸ")
            
            # æµ‹è¯•1: ç»“æ„æ‘˜è¦ï¼ˆä¸ç¼©ç•¥æ˜¾ç¤ºï¼‰
            print("\n1ï¸âƒ£ æµ‹è¯•ç»“æ„æ‘˜è¦ï¼ˆå®Œæ•´æ˜¾ç¤ºï¼‰")
            structure_summary = processor.get_structure_summary()
            
            # ç»Ÿè®¡æ ‡é¢˜å’Œå­—ä½“æ•°é‡
            structure_analysis = analysis_result.get('structure_analysis', {})
            headings = structure_analysis.get('headings', {})
            fonts = structure_analysis.get('fonts_used', [])
            
            total_headings = sum(len(headings[level]) for level in headings.keys())
            print(f"   - æ ‡é¢˜æ€»æ•°: {total_headings}")
            print(f"   - å­—ä½“æ€»æ•°: {len(fonts)}")
            
            if total_headings <= 100:
                print(f"   âœ… æ ‡é¢˜æ•°é‡â‰¤100ï¼Œåº”å…¨éƒ¨æ˜¾ç¤º")
            else:
                print(f"   âš ï¸ æ ‡é¢˜æ•°é‡>100ï¼Œåº”æ˜¾ç¤ºå‰100ä¸ªå¹¶æç¤º")
                
            if len(fonts) <= 100:
                print(f"   âœ… å­—ä½“æ•°é‡â‰¤100ï¼Œåº”å…¨éƒ¨æ˜¾ç¤º")
            else:
                print(f"   âš ï¸ å­—ä½“æ•°é‡>100ï¼Œåº”æ˜¾ç¤ºå‰100ä¸ªå¹¶æç¤º")
            
            # æµ‹è¯•2: å›¾ç‰‡é¢„è§ˆå’Œåˆ†æ
            print("\n2ï¸âƒ£ æµ‹è¯•å›¾ç‰‡é¢„è§ˆå’Œåˆ†æ")
            preview_data = analysis_result.get('preview_data', {})
            has_images = preview_data.get('has_images', False)
            images_preview = preview_data.get('images_preview', [])
            
            print(f"   - æ£€æµ‹åˆ°å›¾ç‰‡: {'æ˜¯' if has_images else 'å¦'}")
            print(f"   - å›¾ç‰‡æ•°é‡: {len(images_preview)}")
            
            if images_preview:
                for i, img_info in enumerate(images_preview, 1):
                    print(f"   - å›¾ç‰‡{i}: {img_info.get('width', 0)}x{img_info.get('height', 0)}px, "
                          f"{img_info.get('size_kb', 0):.1f}KB, "
                          f"æ°´å°: {'æ˜¯' if img_info.get('watermark_detected', False) else 'å¦'}")
            
            # æµ‹è¯•3: æ°´å°æ£€æµ‹
            print("\n3ï¸âƒ£ æµ‹è¯•æ°´å°æ£€æµ‹")
            watermark_analysis = structure_analysis.get('watermark_analysis', {})
            
            if watermark_analysis:
                has_watermark = watermark_analysis.get('has_watermark', False)
                confidence = watermark_analysis.get('confidence', 0)
                watermark_type = watermark_analysis.get('watermark_type', 'æœªçŸ¥')
                
                print(f"   - æ•´ä½“æ°´å°æ£€æµ‹: {'æ£€æµ‹åˆ°' if has_watermark else 'æœªæ£€æµ‹åˆ°'}")
                if has_watermark:
                    print(f"   - ç½®ä¿¡åº¦: {confidence:.2f}")
                    print(f"   - æ°´å°ç±»å‹: {watermark_type}")
                    print(f"   - å«æ°´å°å›¾ç‰‡æ•°: {watermark_analysis.get('watermark_images', 0)}")
            else:
                print("   - æ— æ°´å°åˆ†ææ•°æ®")
            
            print(f"\nâœ… æ–‡ä»¶ {Path(file_path).name} æµ‹è¯•å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()

def test_structure_display_logic():
    """æµ‹è¯•ç»“æ„æ˜¾ç¤ºé€»è¾‘ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    print("\nğŸ” æµ‹è¯•ç»“æ„æ˜¾ç¤ºé€»è¾‘")
    print("-" * 40)
    
    # æ¨¡æ‹Ÿä¸åŒæ•°é‡çš„æ ‡é¢˜å’Œå­—ä½“
    test_cases = [
        {"headings": 5, "fonts": 8, "description": "å°å‹æ–‡æ¡£"},
        {"headings": 50, "fonts": 30, "description": "ä¸­å‹æ–‡æ¡£"},
        {"headings": 100, "fonts": 100, "description": "å¤§å‹æ–‡æ¡£ï¼ˆè¾¹ç•Œå€¼ï¼‰"},
        {"headings": 150, "fonts": 120, "description": "è¶…å¤§å‹æ–‡æ¡£"}
    ]
    
    for case in test_cases:
        print(f"\nğŸ“‹ {case['description']}")
        print(f"   - æ ‡é¢˜æ•°: {case['headings']}")
        print(f"   - å­—ä½“æ•°: {case['fonts']}")
        
        # æ¨¡æ‹Ÿæ˜¾ç¤ºé€»è¾‘
        if case['headings'] <= 100:
            print(f"   âœ… æ ‡é¢˜: å…¨éƒ¨æ˜¾ç¤º ({case['headings']}ä¸ª)")
        else:
            print(f"   âš ï¸ æ ‡é¢˜: æ˜¾ç¤ºå‰100ä¸ªï¼Œæç¤ºè¿˜æœ‰{case['headings'] - 100}ä¸ª")
            
        if case['fonts'] <= 100:
            print(f"   âœ… å­—ä½“: å…¨éƒ¨æ˜¾ç¤º ({case['fonts']}ä¸ª)")
        else:
            print(f"   âš ï¸ å­—ä½“: æ˜¾ç¤ºå‰100ä¸ªï¼Œæç¤ºè¿˜æœ‰{case['fonts'] - 100}ä¸ª")

def test_watermark_detection():
    """æµ‹è¯•æ°´å°æ£€æµ‹ç®—æ³•ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    print("\nğŸ” æµ‹è¯•æ°´å°æ£€æµ‹ç®—æ³•")
    print("-" * 40)
    
    # æ¨¡æ‹Ÿä¸åŒç±»å‹çš„å›¾ç‰‡ç‰¹å¾
    test_images = [
        {
            "name": "æ™®é€šå›¾ç‰‡",
            "variance": 1000,
            "alpha_variation": 10,
            "border_activity": 5,
            "color_imbalance": 1.2
        },
        {
            "name": "é€æ˜æ°´å°å›¾ç‰‡", 
            "variance": 800,
            "alpha_variation": 50,
            "border_activity": 15,
            "color_imbalance": 1.8
        },
        {
            "name": "é‡å¤æ¨¡å¼æ°´å°",
            "variance": 300,
            "alpha_variation": 20,
            "border_activity": 25,
            "color_imbalance": 2.5
        }
    ]
    
    for img in test_images:
        print(f"\nğŸ–¼ï¸ {img['name']}")
        confidence = 0.0
        watermark_type = 'none'
        
        # æ¨¡æ‹Ÿæ£€æµ‹é€»è¾‘
        if img['alpha_variation'] > 30:
            confidence += 0.3
            watermark_type = 'transparent'
            
        if img['variance'] < 500:
            confidence += 0.2
            if watermark_type == 'none':
                watermark_type = 'pattern'
                
        if img['border_activity'] > 20:
            confidence += 0.1
            if watermark_type == 'none':
                watermark_type = 'border'
                
        if img['color_imbalance'] > 2:
            confidence += 0.15
            if watermark_type == 'none':
                watermark_type = 'colored'
        
        has_watermark = confidence > 0.3
        confidence = min(1.0, confidence)
        
        print(f"   - æ°´å°æ£€æµ‹: {'æ˜¯' if has_watermark else 'å¦'}")
        print(f"   - ç½®ä¿¡åº¦: {confidence:.2f}")
        print(f"   - ç±»å‹: {watermark_type}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ æ–‡æ¡£åˆ†æå¢å¼ºåŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    print("æµ‹è¯•åŠŸèƒ½:")
    print("1. ç»“æ„åŒ–åˆ†æä¸ç¼©ç•¥æ˜¾ç¤ºï¼ˆ100ä¸ªä»¥å†…å…¨éƒ¨æ˜¾ç¤ºï¼‰")
    print("2. å›¾ç‰‡é¢„è§ˆå’Œåˆ†æåŠŸèƒ½") 
    print("3. æ°´å°æ£€æµ‹åŠŸèƒ½")
    print("=" * 60)
    
    try:
        # æµ‹è¯•æ–‡æ¡£åˆ†æåŠŸèƒ½
        test_enhanced_document_analysis()
        
        # æµ‹è¯•æ°´å°æ£€æµ‹ç®—æ³•
        test_watermark_detection()
        
        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ")
        print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
        print("1. è¿è¡Œä¸»åº”ç”¨: streamlit run app_enhanced_multiuser.py")
        print("2. é€‰æ‹©'ğŸ“„ æ–‡æ¡£åˆ†æ'æ¨¡å¼")
        print("3. ä¸Šä¼ PDFæˆ–DOCXæ–‡ä»¶")
        print("4. åœ¨'ğŸ“„ æ–‡æ¡£é¢„è§ˆ'æ ‡ç­¾æŸ¥çœ‹å›¾ç‰‡é¢„è§ˆå’Œæ°´å°æ£€æµ‹ç»“æœ")
        print("5. ç»“æ„åˆ†æç»“æœç°åœ¨ä¼šå®Œæ•´æ˜¾ç¤º100ä¸ªä»¥å†…çš„æ‰€æœ‰é¡¹ç›®")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 